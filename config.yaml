chat_model:
  'model': "llama3.2:3b"
  'temperature': 0.75
  'num_gpu': 1


vector_database:
  chroma:


chat_session_path: './chat_session/'